<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Facial Verifier</title>
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    <style>
        :root { --glow: #00f2ff; --bg: rgba(0, 0, 0, 0.8); }
        body, html { margin: 0; padding: 0; width: 100%; height: 100%; background: #000; color: white; font-family: 'Courier New', monospace; overflow: hidden; }
        
        .container { position: relative; width: 100vw; height: 100vh; display: flex; flex-direction: column; align-items: center; }
        video { position: absolute; width: 100%; height: 100%; object-fit: cover; }
        
        .mask {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            background: var(--bg);
            mask: radial-gradient(ellipse 35% 45% at 50% 50%, transparent 98%, black 100%);
            -webkit-mask: radial-gradient(ellipse 35% 45% at 50% 50%, transparent 98%, black 100%);
            z-index: 1;
        }

        .oval-border {
            position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);
            width: 50vh; height: 70vh; border: 2px solid var(--glow); border-radius: 50%;
            box-shadow: 0 0 20px var(--glow); z-index: 2; pointer-events: none;
        }

        .hud { position: absolute; z-index: 10; text-align: center; width: 100%; pointer-events: none; }
        .top { top: 20px; }
        .bottom { bottom: 30px; pointer-events: auto; }

        .status-pill {
            background: rgba(0,0,0,0.6); border: 1px solid var(--glow);
            padding: 8px 20px; display: inline-block; margin-bottom: 15px; min-width: 200px;
        }
        
        .btn {
            background: none; border: 1px solid white; color: white;
            padding: 10px 20px; cursor: pointer; text-transform: uppercase; margin: 0 5px;
        }

        .btn-capture { background: var(--glow); color: black; font-weight: bold; border: none; opacity: 0.3; pointer-events: none; transition: 0.3s; }
        .btn-capture.active { opacity: 1; pointer-events: auto; box-shadow: 0 0 15px var(--glow); }
        
        #hidden-canvas { display: none; }
    </style>
</head>
<body>

    <div class="container">
        <video id="video" autoplay playsinline muted></video>
        <div class="mask"></div>
        <div class="oval-border"></div>

        <div class="hud top">
            <h2 style="letter-spacing: 4px;">FACIAL SCANNER</h2>
            <div id="id-tag" style="font-size: 10px; color: var(--glow);">AI MODULE ACTIVE</div>
        </div>

        <div class="hud bottom">
            <div class="status-pill" id="status">INITIALIZING...</div>
            <br>
            <button class="btn" onclick="flipCamera()">Flip</button>
            <button class="btn btn-capture" id="captureBtn" onclick="saveResult()">Capture</button>
        </div>
    </div>

    <canvas id="hidden-canvas"></canvas>

    <script>
        const video = document.getElementById('video');
        const status = document.getElementById('status');
        const captureBtn = document.getElementById('captureBtn');
        let useFront = true;
        let modelsLoaded = false;

        // 1. Load Models from a reliable GitHub mirror
        async function loadModels() {
            status.innerText = "LOADING AI...";
            const MODEL_URL = 'https://raw.githubusercontent.com/vladmandic/face-api/master/model/';
            try {
                await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
                modelsLoaded = true;
                status.innerText = "MODELS READY";
                startCamera();
            } catch (e) {
                status.innerText = "MODEL LOAD ERROR";
                console.error(e);
            }
        }

        // 2. Camera Controls with explicit play command
        async function startCamera() {
            try {
                if (video.srcObject) {
                    video.srcObject.getTracks().forEach(t => t.stop());
                }
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: useFront ? "user" : "environment" } 
                });
                
                video.srcObject = stream;
                video.style.transform = useFront ? "scaleX(-1)" : "scaleX(1)";
                
                video.onloadedmetadata = () => {
                    video.play();
                    detectFace();
                };
            } catch (e) {
                status.innerText = "CAMERA ACCESS DENIED";
            }
        }

        function flipCamera() {
            useFront = !useFront;
            startCamera();
        }

        // 3. Optimized Real-time Detection
        async function detectFace() {
            if (!modelsLoaded) return;

            const options = new faceapi.TinyFaceDetectorOptions();
            
            // Using a recursive requestAnimationFrame for smoother performance
            async function frameLoop() {
                if (video.paused || video.ended) return;

                const detection = await faceapi.detectSingleFace(video, options);
                
                if (detection) {
                    status.innerText = "FACE DETECTED";
                    status.style.borderColor = "#00ff00";
                    captureBtn.classList.add('active');
                } else {
                    status.innerText = "FRAME FACE";
                    status.style.borderColor = "var(--glow)";
                    captureBtn.classList.remove('active');
                }
                requestAnimationFrame(frameLoop);
            }
            frameLoop();
        }

        // 4. Save Logic
        function saveResult() {
            const canvas = document.getElementById('hidden-canvas');
            const ctx = canvas.getContext('2d');
            const uid = 'ID-' + Math.random().toString(36).toUpperCase().substr(2, 8);

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            if (useFront) {
                ctx.translate(canvas.width, 0);
                ctx.scale(-1, 1);
            }
            ctx.drawImage(video, 0, 0);
            ctx.setTransform(1, 0, 0, 1, 0, 0);

            // Overlay dark area
            ctx.fillStyle = "rgba(0,0,0,0.4)";
            ctx.fillRect(0, 0, canvas.width, 100);

            // Text Info
            ctx.fillStyle = "#00f2ff";
            ctx.font = "bold 24px monospace";
            ctx.fillText("SCAN UID: " + uid, 30, 50);
            ctx.font = "18px monospace";
            ctx.fillText("VERIFIED: " + new Date().toLocaleString(), 30, 80);

            const link = document.createElement('a');
            link.download = `FaceScan_${uid}.png`;
            link.href = canvas.toDataURL('image/png');
            link.click();
        }

        loadModels();
    </script>
</body>
</html>
